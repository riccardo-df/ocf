% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/ordered-ml.R
\name{ordered_ml}
\alias{ordered_ml}
\title{Ordered Machine Learning}
\usage{
ordered_ml(y = NULL, X = NULL, learner = "forest")
}
\arguments{
\item{y}{Outcome vector.}

\item{X}{Covariate matrix (no intercept).}

\item{learner}{String, either \code{"forest"} or \code{"l1"}. Selects the base learner to estimate each expectation.}
}
\value{
Object of class \code{oml}.
}
\description{
Estimation strategy to estimate conditional choice probabilities for ordered non-numeric outcomes.
}
\details{
Ordered machine learning expresses conditional choice probabilities as the difference between the cumulative probabilities 
of two adjacent classes, which in turn can be expressed as conditional expectations of binary variables:

\deqn{p_m \left( X_i \right) = \mathbb{E} \left[ 1 \left( Y_i \leq m \right) | X_i \right] - \mathbb{E} \left[ 1 \left( Y_i \leq m - 1 \right) | X_i \right]}

Then we can separately estimate each expectation using any regression algorithm and pick the difference between the m-th and the
(m-1)-th estimated surfaces to estimate conditional probabilities.

\code{\link{ordered_ml}} combines this strategy with either regression forests or penalized logistic regression with an L1 penalty,
according to the user-specified parameter \code{learner}. If \code{learner == "forest"}, then the \code{\link[orf]{orf}}
function is called from an external package, as this estimator has already been proposed by Lechner and Okasa (2019). If 
\code{learner == "l1"}, the covariates are scaled to have zero mean and unit variance, and the penalty parameters are chosen 
via 10-fold cross-validation. Also, \code{\link[stats]{model.matrix}} is used to handle non-numeric covariates.\cr
}
\examples{
## Load data from orf package.
set.seed(1986)

library(orf)
data(odata)
odata <- odata[1:200, ] # Subset to reduce elapsed time.

y <- as.numeric(odata[, 1])
X <- as.matrix(odata[, -1])

## Training-test split.
train_idx <- sample(seq_len(length(y)), floor(length(y) * 0.5))

y_tr <- y[train_idx]
X_tr <- X[train_idx, ]

y_test <- y[-train_idx]
X_test <- X[-train_idx, ]

## Fit ordered machine learning on training sample using two different learners.
ordered_forest <- ordered_ml(y_tr, X_tr, learner = "forest")
ordered_l1 <- ordered_ml(y_tr, X_tr, learner = "l1")

## Predict out of sample.
predictions_forest <- predict(ordered_forest, X_test)
predictions_l1 <- predict(ordered_l1, X_test)

## Compare predictions.
cbind(head(predictions_forest), head(predictions_l1))

}
\seealso{
\code{\link{multinomial_ml}}, \code{\link{ocf}}
}
\author{
Riccardo Di Francesco
}
