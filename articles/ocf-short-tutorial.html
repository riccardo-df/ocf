<!DOCTYPE html>
<!-- Generated by pkgdown: do not edit by hand --><html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<title>Short Tutorial • ocf</title>
<!-- jquery --><script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.7.1/jquery.min.js" integrity="sha512-v2CJ7UaYy4JwqLDIrZUI/4hqeoQieOmAZNXBeQyjo21dadnwR+8ZaIJVT8EE2iyI61OV8e6M8PP2/4hpQINQ/g==" crossorigin="anonymous" referrerpolicy="no-referrer"></script><!-- Bootstrap --><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/3.4.1/css/bootstrap.min.css" integrity="sha256-bZLfwXAP04zRMK2BjiO8iu9pf4FbLqX6zitd+tIvLhE=" crossorigin="anonymous">
<script src="https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/3.4.1/js/bootstrap.min.js" integrity="sha256-nuL8/2cJ5NDSSwnKD8VqreErSWHtnEP9E7AySL+1ev4=" crossorigin="anonymous"></script><!-- bootstrap-toc --><link rel="stylesheet" href="../bootstrap-toc.css">
<script src="../bootstrap-toc.js"></script><!-- Font Awesome icons --><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.12.1/css/all.min.css" integrity="sha256-mmgLkCYLUQbXn0B1SRqzHar6dCnv9oZFPEC1g1cwlkk=" crossorigin="anonymous">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.12.1/css/v4-shims.min.css" integrity="sha256-wZjR52fzng1pJHwx4aV2AO3yyTOXrcDW7jBpJtTwVxw=" crossorigin="anonymous">
<!-- clipboard.js --><script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.6/clipboard.min.js" integrity="sha256-inc5kl9MA1hkeYUt+EC3BhlIgyp/2jDIyBLS6k3UxPI=" crossorigin="anonymous"></script><!-- headroom.js --><script src="https://cdnjs.cloudflare.com/ajax/libs/headroom/0.11.0/headroom.min.js" integrity="sha256-AsUX4SJE1+yuDu5+mAVzJbuYNPHj/WroHuZ8Ir/CkE0=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/headroom/0.11.0/jQuery.headroom.min.js" integrity="sha256-ZX/yNShbjqsohH1k95liqY9Gd8uOiE1S4vZc+9KQ1K4=" crossorigin="anonymous"></script><!-- pkgdown --><link href="../pkgdown.css" rel="stylesheet">
<script src="../pkgdown.js"></script><meta property="og:title" content="Short Tutorial">
<!-- mathjax --><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js" integrity="sha256-nvJJv9wWKEm88qvoQl9ekL2J+k/RWIsaSScxxlsrv8k=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/config/TeX-AMS-MML_HTMLorMML.js" integrity="sha256-84DKXVJXs0/F8OTMzX4UR909+jtl4G7SPypPavF+GfA=" crossorigin="anonymous"></script><!--[if lt IE 9]>
<script src="https://oss.maxcdn.com/html5shiv/3.7.3/html5shiv.min.js"></script>
<script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
<![endif]-->
</head>
<body data-spy="scroll" data-target="#toc">


    <div class="container template-article">
      <header><div class="navbar navbar-default navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar" aria-expanded="false">
        <span class="sr-only">Toggle navigation</span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <span class="navbar-brand">
        <a class="navbar-link" href="../index.html">ocf</a>
        <span class="version label label-default" data-toggle="tooltip" data-placement="bottom" title="">1.0.3</span>
      </span>
    </div>

    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
<li>
  <a href="../articles/ocf-short-tutorial.html">Get started</a>
</li>
<li>
  <a href="../reference/index.html">Reference</a>
</li>
      </ul>
<ul class="nav navbar-nav navbar-right">
<li>
  <a href="https://github.com/riccardo-df/ocf" class="external-link">
    <span class="fa fa-github fa-lg"></span>

  </a>
</li>
      </ul>
</div>
<!--/.nav-collapse -->
  </div>
<!--/.container -->
</div>
<!--/.navbar -->



      </header><div class="row">
  <div class="col-md-9 contents">
    <div class="page-header toc-ignore">
      <h1 data-toc-skip>Short Tutorial</h1>
            
      
      <small class="dont-index">Source: <a href="https://github.com/riccardo-df/ocf/blob/main/vignettes/ocf-short-tutorial.Rmd" class="external-link"><code>vignettes/ocf-short-tutorial.Rmd</code></a></small>
      <div class="hidden name"><code>ocf-short-tutorial.Rmd</code></div>

    </div>

    
    
<p>In this tutorial, we show how to use the <code>ocf</code> package to
estimate and make inference about the conditional choice probabilities
and the covariates’ marginal effects.</p>
<p>Before diving in the coding, we provide an overview of the
statistical problem at hand.</p>
<div class="section level2">
<h2 id="ordered-choice-models">Ordered Choice Models<a class="anchor" aria-label="anchor" href="#ordered-choice-models"></a>
</h2>
<p>We postulate the existence of a latent and continuous outcome
variable
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msubsup><mi>Y</mi><mi>i</mi><mo>*</mo></msubsup><annotation encoding="application/x-tex">Y_i^*</annotation></semantics></math>,
assumed to obey the following regression model:</p>
<p><math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msubsup><mi>Y</mi><mi>i</mi><mo>*</mo></msubsup><mo>=</mo><mi>g</mi><mrow><mo stretchy="true" form="prefix">(</mo><msub><mi>X</mi><mi>i</mi></msub><mo stretchy="true" form="postfix">)</mo></mrow><mo>+</mo><msub><mi>ϵ</mi><mi>i</mi></msub></mrow><annotation encoding="application/x-tex"> Y_i^* = g \left( X_i \right) + \epsilon_i  </annotation></semantics></math>
where
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>X</mi><mi>i</mi></msub><annotation encoding="application/x-tex">X_i</annotation></semantics></math>
consists of a set of raw covariates,
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>g</mi><mrow><mo stretchy="true" form="prefix">(</mo><mo>⋅</mo><mo stretchy="true" form="postfix">)</mo></mrow></mrow><annotation encoding="application/x-tex">g \left( \cdot \right)</annotation></semantics></math>
is a potentially non-linear regression function, and
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>ϵ</mi><mi>i</mi></msub><annotation encoding="application/x-tex">\epsilon_i</annotation></semantics></math>
is independent of
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>X</mi><mi>i</mi></msub><annotation encoding="application/x-tex">X_i</annotation></semantics></math>.</p>
<p>An observational rule links the observed outcome
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>Y</mi><mi>i</mi></msub><annotation encoding="application/x-tex">Y_i</annotation></semantics></math>
to the latent outcome
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msubsup><mi>Y</mi><mi>i</mi><mo>*</mo></msubsup><annotation encoding="application/x-tex">Y_{i}^*</annotation></semantics></math>
using unknown threshold parameters
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo>−</mo><mi>∞</mi><mo>=</mo><msub><mi>ζ</mi><mn>0</mn></msub><mo>&lt;</mo><msub><mi>ζ</mi><mn>1</mn></msub><mo>&lt;</mo><mi>…</mi><mo>&lt;</mo><msub><mi>ζ</mi><mrow><mi>M</mi><mo>−</mo><mn>1</mn></mrow></msub><mo>&lt;</mo><msub><mi>ζ</mi><mi>M</mi></msub><mo>=</mo><mi>∞</mi></mrow><annotation encoding="application/x-tex">- \infty = \zeta_0 &lt; \zeta_1 &lt; \dots &lt; \zeta_{M - 1} &lt; \zeta_M = \infty</annotation></semantics></math>
that define intervals on the support of
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msubsup><mi>Y</mi><mi>i</mi><mo>*</mo></msubsup><annotation encoding="application/x-tex">Y_i^*</annotation></semantics></math>,
with each interval corresponding to one of the
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>M</mi><annotation encoding="application/x-tex">M</annotation></semantics></math>
categories or classes of
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>Y</mi><mi>i</mi></msub><annotation encoding="application/x-tex">Y_i</annotation></semantics></math>:</p>
<p><math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>ζ</mi><mrow><mi>m</mi><mo>−</mo><mn>1</mn></mrow></msub><mo>&lt;</mo><msubsup><mi>Y</mi><mi>i</mi><mo>*</mo></msubsup><mo>≤</mo><msub><mi>ζ</mi><mi>m</mi></msub><mo>⟹</mo><msub><mi>Y</mi><mi>i</mi></msub><mo>=</mo><mi>m</mi><mo>,</mo><mspace width="1.0em"></mspace><mi>m</mi><mo>=</mo><mn>1</mn><mo>,</mo><mi>…</mi><mo>,</mo><mi>M</mi></mrow><annotation encoding="application/x-tex"> \zeta_{m - 1} &lt; Y_i^* \leq \zeta_{m} \implies Y_i = m, \quad m = 1, \dots, M </annotation></semantics></math></p>
<p>The statistical targets of interest are the conditional choice
probabilities:</p>
<p><math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>p</mi><mi>m</mi></msub><mrow><mo stretchy="true" form="prefix">(</mo><msub><mi>X</mi><mi>i</mi></msub><mo stretchy="true" form="postfix">)</mo></mrow><mo>:=</mo><mi>ℙ</mi><mrow><mo stretchy="true" form="prefix">(</mo><msub><mi>Y</mi><mi>i</mi></msub><mo>=</mo><mi>m</mi><mo stretchy="false" form="prefix">|</mo><msub><mi>X</mi><mi>i</mi></msub><mo stretchy="true" form="postfix">)</mo></mrow></mrow><annotation encoding="application/x-tex"> p_m \left( X_i \right) := \mathbb{P} \left( Y_i = m | X_i \right) </annotation></semantics></math></p>
<p>and the marginal effect of the
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>j</mi><annotation encoding="application/x-tex">j</annotation></semantics></math>-th
covariate on
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>p</mi><mi>m</mi></msub><mrow><mo stretchy="true" form="prefix">(</mo><mo>⋅</mo><mo stretchy="true" form="postfix">)</mo></mrow></mrow><annotation encoding="application/x-tex">p_m \left( \cdot \right)</annotation></semantics></math>:</p>
<p><math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mi>∇</mi><mi>j</mi></msup><msub><mi>p</mi><mi>m</mi></msub><mrow><mo stretchy="true" form="prefix">(</mo><mi>x</mi><mo stretchy="true" form="postfix">)</mo></mrow><mo>:=</mo><mrow><mo stretchy="true" form="prefix">{</mo><mtable><mtr><mtd columnalign="left" style="text-align: left"><mfrac><mrow><mi>∂</mi><msub><mi>p</mi><mi>m</mi></msub><mrow><mo stretchy="true" form="prefix">(</mo><mi>x</mi><mo stretchy="true" form="postfix">)</mo></mrow></mrow><mrow><mi>∂</mi><msub><mi>x</mi><mi>j</mi></msub></mrow></mfrac><mo>,</mo></mtd><mtd columnalign="left" style="text-align: left"><mrow><mtext mathvariant="normal">if </mtext><mspace width="0.333em"></mspace></mrow><msub><mi>x</mi><mi>j</mi></msub><mrow><mspace width="0.333em"></mspace><mtext mathvariant="normal"> is continuous</mtext></mrow></mtd></mtr><mtr><mtd columnalign="left" style="text-align: left"><msub><mi>p</mi><mi>m</mi></msub><mrow><mo stretchy="true" form="prefix">(</mo><mo stretchy="false" form="prefix">⌈</mo><msub><mi>x</mi><mi>j</mi></msub><mo stretchy="false" form="postfix">⌉</mo><mo stretchy="true" form="postfix">)</mo></mrow><mo>−</mo><msub><mi>p</mi><mi>m</mi></msub><mrow><mo stretchy="true" form="prefix">(</mo><mo stretchy="false" form="prefix">⌊</mo><msub><mi>x</mi><mi>j</mi></msub><mo stretchy="false" form="postfix">⌋</mo><mo stretchy="true" form="postfix">)</mo></mrow><mo>,</mo></mtd><mtd columnalign="left" style="text-align: left"><mrow><mtext mathvariant="normal">if </mtext><mspace width="0.333em"></mspace></mrow><msub><mi>x</mi><mi>j</mi></msub><mrow><mspace width="0.333em"></mspace><mtext mathvariant="normal"> is discrete</mtext></mrow></mtd></mtr></mtable></mrow></mrow><annotation encoding="application/x-tex">
\nabla^j p_m \left( x \right) := 
  \begin{cases}
    \frac{\partial p_m \left( x \right)}{\partial x_j}, &amp; \text{if } x_j \text{ is continuous}  \\
    p_m \left( \lceil x_j \rceil \right) - p_m \left( \lfloor x_j \rfloor \right), &amp; \text{if } x_j \text{ is discrete}
  \end{cases}
</annotation></semantics></math> where
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>x</mi><mi>j</mi></msub><annotation encoding="application/x-tex">x_j</annotation></semantics></math>
is the
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>j</mi><annotation encoding="application/x-tex">j</annotation></semantics></math>-th
element of the vector
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>x</mi><annotation encoding="application/x-tex">x</annotation></semantics></math>
and
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false" form="prefix">⌈</mo><msub><mi>x</mi><mi>j</mi></msub><mo stretchy="false" form="postfix">⌉</mo></mrow><annotation encoding="application/x-tex">\lceil x_j \rceil</annotation></semantics></math>
and
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false" form="prefix">⌊</mo><msub><mi>x</mi><mi>j</mi></msub><mo stretchy="false" form="postfix">⌋</mo></mrow><annotation encoding="application/x-tex">\lfloor x_j \rfloor</annotation></semantics></math>
correspond to
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>x</mi><annotation encoding="application/x-tex">x</annotation></semantics></math>
with its
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>j</mi><annotation encoding="application/x-tex">j</annotation></semantics></math>-th
element rounded up and down to the closest integer.</p>
</div>
<div class="section level2">
<h2 id="code">Code<a class="anchor" aria-label="anchor" href="#code"></a>
</h2>
<p>For illustration purposes, we generate a synthetic data set. Details
about the employed DGP can be retrieved by running
<code><a href="../reference/generate_ordered_data.html">help(generate_ordered_data)</a></code>.</p>
<div class="sourceCode" id="cb1"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1-1"><a href="#cb1-1" tabindex="-1"></a><span class="do">## Generate synthetic data.</span></span>
<span id="cb1-2"><a href="#cb1-2" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">1986</span>)</span>
<span id="cb1-3"><a href="#cb1-3" tabindex="-1"></a></span>
<span id="cb1-4"><a href="#cb1-4" tabindex="-1"></a>n <span class="ot">&lt;-</span> <span class="dv">100</span></span>
<span id="cb1-5"><a href="#cb1-5" tabindex="-1"></a>data <span class="ot">&lt;-</span> <span class="fu">generate_ordered_data</span>(n)</span>
<span id="cb1-6"><a href="#cb1-6" tabindex="-1"></a></span>
<span id="cb1-7"><a href="#cb1-7" tabindex="-1"></a>sample <span class="ot">&lt;-</span> data<span class="sc">$</span>sample</span>
<span id="cb1-8"><a href="#cb1-8" tabindex="-1"></a>Y <span class="ot">&lt;-</span> sample<span class="sc">$</span>Y</span>
<span id="cb1-9"><a href="#cb1-9" tabindex="-1"></a>X <span class="ot">&lt;-</span> sample[, <span class="sc">-</span><span class="dv">1</span>]</span>
<span id="cb1-10"><a href="#cb1-10" tabindex="-1"></a></span>
<span id="cb1-11"><a href="#cb1-11" tabindex="-1"></a><span class="fu">table</span>(Y)</span>
<span id="cb1-12"><a href="#cb1-12" tabindex="-1"></a>Y</span>
<span id="cb1-13"><a href="#cb1-13" tabindex="-1"></a> <span class="dv">1</span>  <span class="dv">2</span>  <span class="dv">3</span> </span>
<span id="cb1-14"><a href="#cb1-14" tabindex="-1"></a><span class="dv">31</span> <span class="dv">37</span> <span class="dv">32</span> </span>
<span id="cb1-15"><a href="#cb1-15" tabindex="-1"></a></span>
<span id="cb1-16"><a href="#cb1-16" tabindex="-1"></a><span class="fu">head</span>(X)</span>
<span id="cb1-17"><a href="#cb1-17" tabindex="-1"></a>           x1 x2         x3 x4            x5 x6</span>
<span id="cb1-18"><a href="#cb1-18" tabindex="-1"></a><span class="dv">1</span> <span class="sc">-</span><span class="fl">0.04625141</span>  <span class="dv">1</span> <span class="sc">-</span><span class="fl">1.7879732</span>  <span class="dv">0</span> <span class="sc">-</span><span class="fl">1.0515868012</span>  <span class="dv">1</span></span>
<span id="cb1-19"><a href="#cb1-19" tabindex="-1"></a><span class="dv">2</span>  <span class="fl">0.28000082</span>  <span class="dv">0</span> <span class="sc">-</span><span class="fl">1.1553030</span>  <span class="dv">0</span> <span class="sc">-</span><span class="fl">0.4285613418</span>  <span class="dv">0</span></span>
<span id="cb1-20"><a href="#cb1-20" tabindex="-1"></a><span class="dv">3</span>  <span class="fl">0.25317063</span>  <span class="dv">1</span>  <span class="fl">1.6677330</span>  <span class="dv">0</span>  <span class="fl">0.1621459072</span>  <span class="dv">0</span></span>
<span id="cb1-21"><a href="#cb1-21" tabindex="-1"></a><span class="dv">4</span> <span class="sc">-</span><span class="fl">0.96411077</span>  <span class="dv">0</span> <span class="sc">-</span><span class="fl">0.1587051</span>  <span class="dv">0</span>  <span class="fl">0.3587438820</span>  <span class="dv">0</span></span>
<span id="cb1-22"><a href="#cb1-22" tabindex="-1"></a><span class="dv">5</span>  <span class="fl">0.49222664</span>  <span class="dv">0</span> <span class="sc">-</span><span class="fl">1.4020533</span>  <span class="dv">1</span>  <span class="fl">0.0004035277</span>  <span class="dv">0</span></span>
<span id="cb1-23"><a href="#cb1-23" tabindex="-1"></a><span class="dv">6</span> <span class="sc">-</span><span class="fl">0.69874551</span>  <span class="dv">1</span> <span class="sc">-</span><span class="fl">0.4450061</span>  <span class="dv">0</span> <span class="sc">-</span><span class="fl">0.3183447897</span>  <span class="dv">0</span></span></code></pre></div>
<div class="section level3">
<h3 id="conditional-probabilities">Conditional Probabilities<a class="anchor" aria-label="anchor" href="#conditional-probabilities"></a>
</h3>
<p>To estimate the conditional probabilities, the <code>ocf</code>
function constructs a collection of forests, one for each category of
<code>Y</code> (three in this case). We can then use the forests to
predict out-of-sample using the <code>predict</code> method.
<code>predict</code> returns a matrix with the predicted probabilities
and a vector of predicted class labels (each observation is labelled to
the highest-probability class).</p>
<div class="sourceCode" id="cb2"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2-1"><a href="#cb2-1" tabindex="-1"></a><span class="do">## Training-test split.</span></span>
<span id="cb2-2"><a href="#cb2-2" tabindex="-1"></a>train_idx <span class="ot">&lt;-</span> <span class="fu">sample</span>(<span class="fu">seq_len</span>(<span class="fu">length</span>(Y)), <span class="fu">floor</span>(<span class="fu">length</span>(Y) <span class="sc">*</span> <span class="fl">0.5</span>))</span>
<span id="cb2-3"><a href="#cb2-3" tabindex="-1"></a></span>
<span id="cb2-4"><a href="#cb2-4" tabindex="-1"></a>Y_tr <span class="ot">&lt;-</span> Y[train_idx]</span>
<span id="cb2-5"><a href="#cb2-5" tabindex="-1"></a>X_tr <span class="ot">&lt;-</span> X[train_idx, ]</span>
<span id="cb2-6"><a href="#cb2-6" tabindex="-1"></a></span>
<span id="cb2-7"><a href="#cb2-7" tabindex="-1"></a>Y_test <span class="ot">&lt;-</span> Y[<span class="sc">-</span>train_idx]</span>
<span id="cb2-8"><a href="#cb2-8" tabindex="-1"></a>X_test <span class="ot">&lt;-</span> X[<span class="sc">-</span>train_idx, ]</span>
<span id="cb2-9"><a href="#cb2-9" tabindex="-1"></a></span>
<span id="cb2-10"><a href="#cb2-10" tabindex="-1"></a><span class="do">## Fit ocf on training sample. Use default settings.</span></span>
<span id="cb2-11"><a href="#cb2-11" tabindex="-1"></a>forests <span class="ot">&lt;-</span> <span class="fu">ocf</span>(Y_tr, X_tr)</span>
<span id="cb2-12"><a href="#cb2-12" tabindex="-1"></a></span>
<span id="cb2-13"><a href="#cb2-13" tabindex="-1"></a><span class="do">## Summary of data and tuning parameters.</span></span>
<span id="cb2-14"><a href="#cb2-14" tabindex="-1"></a><span class="fu">summary</span>(forests)</span>
<span id="cb2-15"><a href="#cb2-15" tabindex="-1"></a>Call<span class="sc">:</span> </span>
<span id="cb2-16"><a href="#cb2-16" tabindex="-1"></a><span class="fu">ocf</span>(Y_tr, X_tr) </span>
<span id="cb2-17"><a href="#cb2-17" tabindex="-1"></a></span>
<span id="cb2-18"><a href="#cb2-18" tabindex="-1"></a>Data info<span class="sc">:</span> </span>
<span id="cb2-19"><a href="#cb2-19" tabindex="-1"></a>Full sample size<span class="sc">:</span>   <span class="dv">50</span> </span>
<span id="cb2-20"><a href="#cb2-20" tabindex="-1"></a>N. covariates<span class="sc">:</span>      <span class="dv">6</span> </span>
<span id="cb2-21"><a href="#cb2-21" tabindex="-1"></a>Classes<span class="sc">:</span>            <span class="dv">1</span> <span class="dv">2</span> <span class="dv">3</span> </span>
<span id="cb2-22"><a href="#cb2-22" tabindex="-1"></a></span>
<span id="cb2-23"><a href="#cb2-23" tabindex="-1"></a>Relative variable importance<span class="sc">:</span> </span>
<span id="cb2-24"><a href="#cb2-24" tabindex="-1"></a>   x1    x2    x3    x4    x5    x6 </span>
<span id="cb2-25"><a href="#cb2-25" tabindex="-1"></a><span class="fl">0.369</span> <span class="fl">0.075</span> <span class="fl">0.253</span> <span class="fl">0.101</span> <span class="fl">0.172</span> <span class="fl">0.030</span> </span>
<span id="cb2-26"><a href="#cb2-26" tabindex="-1"></a></span>
<span id="cb2-27"><a href="#cb2-27" tabindex="-1"></a>Tuning parameters<span class="sc">:</span> </span>
<span id="cb2-28"><a href="#cb2-28" tabindex="-1"></a>N. trees<span class="sc">:</span>           <span class="dv">2000</span> </span>
<span id="cb2-29"><a href="#cb2-29" tabindex="-1"></a>mtry<span class="sc">:</span>               <span class="dv">3</span> </span>
<span id="cb2-30"><a href="#cb2-30" tabindex="-1"></a>min.node.size       <span class="dv">5</span> </span>
<span id="cb2-31"><a href="#cb2-31" tabindex="-1"></a>Subsampling scheme<span class="sc">:</span> No replacement </span>
<span id="cb2-32"><a href="#cb2-32" tabindex="-1"></a>Honesty<span class="sc">:</span>            <span class="cn">FALSE</span> </span>
<span id="cb2-33"><a href="#cb2-33" tabindex="-1"></a>Honest fraction<span class="sc">:</span>    <span class="dv">0</span></span>
<span id="cb2-34"><a href="#cb2-34" tabindex="-1"></a></span>
<span id="cb2-35"><a href="#cb2-35" tabindex="-1"></a><span class="do">## Out-of-sample predictions.</span></span>
<span id="cb2-36"><a href="#cb2-36" tabindex="-1"></a>predictions <span class="ot">&lt;-</span> <span class="fu">predict</span>(forests, X_test)</span>
<span id="cb2-37"><a href="#cb2-37" tabindex="-1"></a></span>
<span id="cb2-38"><a href="#cb2-38" tabindex="-1"></a><span class="fu">head</span>(predictions<span class="sc">$</span>probabilities)</span>
<span id="cb2-39"><a href="#cb2-39" tabindex="-1"></a>        <span class="fu">P</span>(<span class="at">Y=</span><span class="dv">1</span>)    <span class="fu">P</span>(<span class="at">Y=</span><span class="dv">2</span>)     <span class="fu">P</span>(<span class="at">Y=</span><span class="dv">3</span>)</span>
<span id="cb2-40"><a href="#cb2-40" tabindex="-1"></a>[<span class="dv">1</span>,] <span class="fl">0.3543743</span> <span class="fl">0.5375517</span> <span class="fl">0.10807401</span></span>
<span id="cb2-41"><a href="#cb2-41" tabindex="-1"></a>[<span class="dv">2</span>,] <span class="fl">0.4571570</span> <span class="fl">0.4057421</span> <span class="fl">0.13710091</span></span>
<span id="cb2-42"><a href="#cb2-42" tabindex="-1"></a>[<span class="dv">3</span>,] <span class="fl">0.1173914</span> <span class="fl">0.4803692</span> <span class="fl">0.40223943</span></span>
<span id="cb2-43"><a href="#cb2-43" tabindex="-1"></a>[<span class="dv">4</span>,] <span class="fl">0.6342519</span> <span class="fl">0.3132168</span> <span class="fl">0.05253126</span></span>
<span id="cb2-44"><a href="#cb2-44" tabindex="-1"></a>[<span class="dv">5</span>,] <span class="fl">0.3482501</span> <span class="fl">0.3873043</span> <span class="fl">0.26444560</span></span>
<span id="cb2-45"><a href="#cb2-45" tabindex="-1"></a>[<span class="dv">6</span>,] <span class="fl">0.6284292</span> <span class="fl">0.2999011</span> <span class="fl">0.07166965</span></span>
<span id="cb2-46"><a href="#cb2-46" tabindex="-1"></a></span>
<span id="cb2-47"><a href="#cb2-47" tabindex="-1"></a><span class="fu">table</span>(Y_test, predictions<span class="sc">$</span>classification)</span>
<span id="cb2-48"><a href="#cb2-48" tabindex="-1"></a>      </span>
<span id="cb2-49"><a href="#cb2-49" tabindex="-1"></a>Y_test  <span class="dv">1</span>  <span class="dv">2</span>  <span class="dv">3</span></span>
<span id="cb2-50"><a href="#cb2-50" tabindex="-1"></a>     <span class="dv">1</span> <span class="dv">12</span>  <span class="dv">3</span>  <span class="dv">1</span></span>
<span id="cb2-51"><a href="#cb2-51" tabindex="-1"></a>     <span class="dv">2</span>  <span class="dv">6</span>  <span class="dv">6</span>  <span class="dv">7</span></span>
<span id="cb2-52"><a href="#cb2-52" tabindex="-1"></a>     <span class="dv">3</span>  <span class="dv">3</span>  <span class="dv">2</span> <span class="dv">10</span></span></code></pre></div>
<p>To produce consistent and asymptotically normal predictions, we need
to set the <code>honesty</code> argument to TRUE. This makes the
<code>ocf</code> function using different parts of the training sample
to construct the forests and compute the predictions.</p>
<div class="sourceCode" id="cb3"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb3-1"><a href="#cb3-1" tabindex="-1"></a><span class="do">## Honest forests.</span></span>
<span id="cb3-2"><a href="#cb3-2" tabindex="-1"></a>honest_forests <span class="ot">&lt;-</span> <span class="fu">ocf</span>(Y_tr, X_tr, <span class="at">honesty =</span> <span class="cn">TRUE</span>)</span>
<span id="cb3-3"><a href="#cb3-3" tabindex="-1"></a></span>
<span id="cb3-4"><a href="#cb3-4" tabindex="-1"></a>honest_predictions <span class="ot">&lt;-</span> <span class="fu">predict</span>(honest_forests, X_test)</span>
<span id="cb3-5"><a href="#cb3-5" tabindex="-1"></a><span class="fu">head</span>(honest_predictions<span class="sc">$</span>probabilities)</span>
<span id="cb3-6"><a href="#cb3-6" tabindex="-1"></a>        <span class="fu">P</span>(<span class="at">Y=</span><span class="dv">1</span>)    <span class="fu">P</span>(<span class="at">Y=</span><span class="dv">2</span>)    <span class="fu">P</span>(<span class="at">Y=</span><span class="dv">3</span>)</span>
<span id="cb3-7"><a href="#cb3-7" tabindex="-1"></a>[<span class="dv">1</span>,] <span class="fl">0.3476025</span> <span class="fl">0.3216374</span> <span class="fl">0.3307601</span></span>
<span id="cb3-8"><a href="#cb3-8" tabindex="-1"></a>[<span class="dv">2</span>,] <span class="fl">0.3865934</span> <span class="fl">0.3244973</span> <span class="fl">0.2889093</span></span>
<span id="cb3-9"><a href="#cb3-9" tabindex="-1"></a>[<span class="dv">3</span>,] <span class="fl">0.2351550</span> <span class="fl">0.4112832</span> <span class="fl">0.3535617</span></span>
<span id="cb3-10"><a href="#cb3-10" tabindex="-1"></a>[<span class="dv">4</span>,] <span class="fl">0.4237396</span> <span class="fl">0.3527212</span> <span class="fl">0.2235392</span></span>
<span id="cb3-11"><a href="#cb3-11" tabindex="-1"></a>[<span class="dv">5</span>,] <span class="fl">0.3394056</span> <span class="fl">0.3034435</span> <span class="fl">0.3571509</span></span>
<span id="cb3-12"><a href="#cb3-12" tabindex="-1"></a>[<span class="dv">6</span>,] <span class="fl">0.4069484</span> <span class="fl">0.3231956</span> <span class="fl">0.2698560</span></span></code></pre></div>
<p>To estimate standard errors for the predicted probabilities, we need
to set the <code>inference</code> argument to TRUE. However, this works
only if <code>honesty</code> is TRUE, as the formula for the variance is
valid only for honest predictions. Notice that the estimation of the
standard errors can considerably slow down the routine. However, we can
increase the number of threads used to construct the forests by using
the <code>n.threads</code> argument.</p>
<div class="sourceCode" id="cb4"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co">## Compute standard errors. Do not run.</span></span>
<span><span class="co"># honest_forests &lt;- ocf(Y_tr, X_tr, honesty = TRUE, inference = TRUE, n.threads = 0) # Use all CPUs.</span></span>
<span><span class="co"># head(honest_forests$predictions$standard.errors)</span></span></code></pre></div>
</div>
<div class="section level3">
<h3 id="covariates-marginal-effects">Covariates’ Marginal Effects<a class="anchor" aria-label="anchor" href="#covariates-marginal-effects"></a>
</h3>
<p>To estimate the covariates’ marginal effects, we post-process the
conditional probability predictions. This is performed by the
<code>marginal_effects</code> function that can estimate mean marginal
effects, marginal effects at the mean, and marginal effects at the
median, according to the <code>eval</code> argument.</p>
<div class="sourceCode" id="cb5"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb5-1"><a href="#cb5-1" tabindex="-1"></a><span class="do">## Marginal effects at the mean.</span></span>
<span id="cb5-2"><a href="#cb5-2" tabindex="-1"></a>me_atmean <span class="ot">&lt;-</span> <span class="fu">marginal_effects</span>(forests, <span class="at">eval =</span> <span class="st">"atmean"</span>) <span class="co"># Try also 'eval = "atmean"' and 'eval = "mean"'.</span></span>
<span id="cb5-3"><a href="#cb5-3" tabindex="-1"></a><span class="fu">print</span>(me_atmean) <span class="co"># Try also 'latex = TRUE'.</span></span>
<span id="cb5-4"><a href="#cb5-4" tabindex="-1"></a>ocf marginal effects results </span>
<span id="cb5-5"><a href="#cb5-5" tabindex="-1"></a></span>
<span id="cb5-6"><a href="#cb5-6" tabindex="-1"></a>Data info<span class="sc">:</span> </span>
<span id="cb5-7"><a href="#cb5-7" tabindex="-1"></a>Number of classes<span class="sc">:</span>    <span class="dv">3</span> </span>
<span id="cb5-8"><a href="#cb5-8" tabindex="-1"></a>Sample size<span class="sc">:</span>          <span class="dv">50</span> </span>
<span id="cb5-9"><a href="#cb5-9" tabindex="-1"></a></span>
<span id="cb5-10"><a href="#cb5-10" tabindex="-1"></a>Tuning parameters<span class="sc">:</span> </span>
<span id="cb5-11"><a href="#cb5-11" tabindex="-1"></a>Evaluation<span class="sc">:</span>           atmean </span>
<span id="cb5-12"><a href="#cb5-12" tabindex="-1"></a>Bandwidth<span class="sc">:</span>            <span class="fl">0.1</span> </span>
<span id="cb5-13"><a href="#cb5-13" tabindex="-1"></a>Number of trees<span class="sc">:</span>      <span class="dv">2000</span> </span>
<span id="cb5-14"><a href="#cb5-14" tabindex="-1"></a>Honest forests<span class="sc">:</span>       <span class="cn">FALSE</span> </span>
<span id="cb5-15"><a href="#cb5-15" tabindex="-1"></a>Honesty fraction<span class="sc">:</span>     <span class="dv">0</span> </span>
<span id="cb5-16"><a href="#cb5-16" tabindex="-1"></a></span>
<span id="cb5-17"><a href="#cb5-17" tabindex="-1"></a>Marginal Effects<span class="sc">:</span> </span>
<span id="cb5-18"><a href="#cb5-18" tabindex="-1"></a>   P<span class="st">'(Y=1) P'</span>(<span class="at">Y=</span><span class="dv">2</span>) P<span class="st">'(Y=3)</span></span>
<span id="cb5-19"><a href="#cb5-19" tabindex="-1"></a><span class="st">x1  -0.119  -0.283   0.402</span></span>
<span id="cb5-20"><a href="#cb5-20" tabindex="-1"></a><span class="st">x2  -0.986   0.724   0.262</span></span>
<span id="cb5-21"><a href="#cb5-21" tabindex="-1"></a><span class="st">x3  -0.058  -0.027   0.085</span></span>
<span id="cb5-22"><a href="#cb5-22" tabindex="-1"></a><span class="st">x4  -0.507  -1.498   2.006</span></span>
<span id="cb5-23"><a href="#cb5-23" tabindex="-1"></a><span class="st">x5   0.028   0.048  -0.075</span></span>
<span id="cb5-24"><a href="#cb5-24" tabindex="-1"></a><span class="st">x6   0.000   0.000   0.000</span></span>
<span id="cb5-25"><a href="#cb5-25" tabindex="-1"></a><span class="st">plot(me_atmean)</span></span></code></pre></div>
<p><img src="ocf-short-tutorial_files/figure-html/adaptive-me-1.png" width="700"></p>
<p>Sometimes, we are only interested in the marginal effects of a subset
of the available covariates. To spare some time, we can use the
<code>these_covariates</code> argument to estimate marginal effects of
only those covariates. This argument also allows the user to declare
whether the covariates are to be treated as <code>"continuous"</code> of
<code>"discrete"</code> (marginal effect estimation is handled
differently according to the covariate’s nature).
<code>these_covariates</code> must be a named list, with entries’ names
specifying the target covariates and entries specifying the covariates’
types. If not used, covariates’ types are inferred by the routine using
basic heuristics (as in the example above).</p>
<div class="sourceCode" id="cb6"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co">## Marginal effects at the mean.</span></span>
<span><span class="va">target_covariates</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/list.html" class="external-link">list</a></span><span class="op">(</span><span class="st">"x1"</span> <span class="op">=</span> <span class="st">"continuous"</span>, <span class="st">"x2"</span> <span class="op">=</span> <span class="st">"discrete"</span>, <span class="st">"x4"</span> <span class="op">=</span> <span class="st">"discrete"</span><span class="op">)</span></span>
<span><span class="va">me_atmean</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/marginal_effects.html">marginal_effects</a></span><span class="op">(</span><span class="va">forests</span>, eval <span class="op">=</span> <span class="st">"atmean"</span>, these_covariates <span class="op">=</span> <span class="va">target_covariates</span><span class="op">)</span> </span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html" class="external-link">plot</a></span><span class="op">(</span><span class="va">me_atmean</span><span class="op">)</span></span></code></pre></div>
<p><img src="ocf-short-tutorial_files/figure-html/adaptive-me-target-1.png" width="700"></p>
<p>As before, we can set the <code>inference</code> argument to TRUE to
estimate the standard errors. Again, this requires the use of honest
forests and can considerably slow down the routine.</p>
<div class="sourceCode" id="cb7"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb7-1"><a href="#cb7-1" tabindex="-1"></a><span class="do">## Compute standard errors.</span></span>
<span id="cb7-2"><a href="#cb7-2" tabindex="-1"></a>honest_me_atmean <span class="ot">&lt;-</span> <span class="fu">marginal_effects</span>(honest_forests, <span class="at">eval =</span> <span class="st">"atmean"</span>, <span class="at">inference =</span> <span class="cn">TRUE</span>)</span>
<span id="cb7-3"><a href="#cb7-3" tabindex="-1"></a><span class="fu">print</span>(honest_me_atmean) <span class="co"># Try also 'latex = TRUE'.</span></span>
<span id="cb7-4"><a href="#cb7-4" tabindex="-1"></a>ocf marginal effects results </span>
<span id="cb7-5"><a href="#cb7-5" tabindex="-1"></a></span>
<span id="cb7-6"><a href="#cb7-6" tabindex="-1"></a>Data info<span class="sc">:</span> </span>
<span id="cb7-7"><a href="#cb7-7" tabindex="-1"></a>Number of classes<span class="sc">:</span>    <span class="dv">3</span> </span>
<span id="cb7-8"><a href="#cb7-8" tabindex="-1"></a>Sample size<span class="sc">:</span>          <span class="dv">50</span> </span>
<span id="cb7-9"><a href="#cb7-9" tabindex="-1"></a></span>
<span id="cb7-10"><a href="#cb7-10" tabindex="-1"></a>Tuning parameters<span class="sc">:</span> </span>
<span id="cb7-11"><a href="#cb7-11" tabindex="-1"></a>Evaluation<span class="sc">:</span>           atmean </span>
<span id="cb7-12"><a href="#cb7-12" tabindex="-1"></a>Bandwidth<span class="sc">:</span>            <span class="fl">0.1</span> </span>
<span id="cb7-13"><a href="#cb7-13" tabindex="-1"></a>Number of trees<span class="sc">:</span>      <span class="dv">2000</span> </span>
<span id="cb7-14"><a href="#cb7-14" tabindex="-1"></a>Honest forests<span class="sc">:</span>       <span class="cn">TRUE</span> </span>
<span id="cb7-15"><a href="#cb7-15" tabindex="-1"></a>Honesty fraction<span class="sc">:</span>     <span class="fl">0.5</span> </span>
<span id="cb7-16"><a href="#cb7-16" tabindex="-1"></a></span>
<span id="cb7-17"><a href="#cb7-17" tabindex="-1"></a>Marginal Effects<span class="sc">:</span> </span>
<span id="cb7-18"><a href="#cb7-18" tabindex="-1"></a>   P<span class="st">'(Y=1) P'</span>(<span class="at">Y=</span><span class="dv">2</span>) P<span class="st">'(Y=3)</span></span>
<span id="cb7-19"><a href="#cb7-19" tabindex="-1"></a><span class="st">x1  -0.018  -0.009   0.027</span></span>
<span id="cb7-20"><a href="#cb7-20" tabindex="-1"></a><span class="st">x2  -0.368   0.115   0.254</span></span>
<span id="cb7-21"><a href="#cb7-21" tabindex="-1"></a><span class="st">x3  -0.015   0.006   0.009</span></span>
<span id="cb7-22"><a href="#cb7-22" tabindex="-1"></a><span class="st">x4  -0.132  -0.490   0.622</span></span>
<span id="cb7-23"><a href="#cb7-23" tabindex="-1"></a><span class="st">x5  -0.003   0.030  -0.027</span></span>
<span id="cb7-24"><a href="#cb7-24" tabindex="-1"></a><span class="st">x6   0.000   0.000   0.000</span></span>
<span id="cb7-25"><a href="#cb7-25" tabindex="-1"></a><span class="st">plot(me_atmean)</span></span></code></pre></div>
<p><img src="ocf-short-tutorial_files/figure-html/honest-me-1.png" width="700"></p>
</div>
</div>
  </div>

  <div class="col-md-3 hidden-xs hidden-sm" id="pkgdown-sidebar">

      </div>

</div>



      <footer><div class="copyright">
  <p></p>
<p>Developed by Riccardo Di Francesco.</p>
</div>

<div class="pkgdown">
  <p></p>
<p>Site built with <a href="https://pkgdown.r-lib.org/" class="external-link">pkgdown</a> 2.1.1.</p>
</div>

      </footer>
</div>






  </body>
</html>
